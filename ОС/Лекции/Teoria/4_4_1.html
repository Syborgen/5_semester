
<html> 

<body lang=RU>

<h1 align="center">Файловая подсистема</h1> 

<p>Большинство данных в операционной системе UNIX хранится в файлах, организованных в виде дерева и
расположенных на некотором носителе данных. Обычно это локальный (т. е.
расположенный на том же компью&shy;тере, что и сама операционная система) жесткий
диск, хотя специальный тип файловой системы — NFS (Network File System) обеспечивает хране&shy;ние файлов на удаленном компьютере. Файловая
система также может располагаться на CD-ROM, дискетах и других типах носителей, однако для простоты
изложения сначала мы рассмотрим традиционную файловую систему UNIX, расположенную на обычном жестком диске компьютера.</p> 

<p>&nbsp;Исконной файловой системой UNIX System V является s5fs.&nbsp; Файловая система,
разработанная в Беркли, FFS, появилась
позже, в версии 4.2BSD UNIX. По сравнению с s5fs она обладает лучшей 
производительностью, функциональностью
и надежностью. Файловые системы современных версий UNIX имеют весьма сложную архитектуру,
различную для разных версий. Несмотря на это все они используют базовые идеи,
заложенные разработчиками UNIX в AT&amp;T и Калифорнийском университете в Беркли.
Поэтому мы проиллюстрируем основные принципы организации файловой системы UNIX на примере базовых систем System V (s5fs) и BSD (FFS), которые,
кстати, и сегодня поддерживаются в большинстве версий UNIX.</p> 

<p>&nbsp;Когда появилась файловая система FFS, архитектура UNIX поддерживала
работу только с одним типом файловой системы. Таким образом, создатели
различных версий операционной системы UNIX вынуждены были
выбирать одну файловую систему из нескольких возможных. Это неудобство было
преодолено введением <i>независимой </i>или <i>виртуальной файловой системы </i>-
архитектуры, позволяющей обеспечивать работу с несколькими “физическими”
файловыми системами различных типов. В этой главе мы рассмотрим реализацию
виртуальной файловой системы, разработанную фирмой Sun Microsystems. Данная
архитектура является стандартом для SVR4, однако и другие версии UNIX используют подобные подходы. В качестве примера можно
привести независимую файловую систему SCO UNIX.</p> 

<p>&nbsp;Далее
мы рассмотрим схему доступа прикладных процессов к файлам – всю цепочку
структур данных от файловых дескрипторов процесса до фактических дисковых
данных, которую операционная система создает в
результате открытия процессом файла и которая затем
используется для обмена данными.</p> 

<p>&nbsp;В заключение мы рассмотрим буферный кэш — подсистему,
которая позволяет значительно увеличить производительность работы с дисковыми
данными.</p> 

<h3>Базовая файловая система System V</h3> 

<p>Каждый жесткий диск состоит из одной или нескольких
логических час&shy;тей, называемых <i>разделами </i>(partitions). Расположение и размер раздела оп&shy;ределяются при форматировании
диска. В UNIX разделы выступают в ка&shy;честве
независимых устройств, доступ к которым осуществляется как к различным
носителям данных.</p> 

<p>Например, диск может состоять из четырех разделов, каждый
из которых содержит свою файловую систему. Заметим, что в разделе может распола&shy;гаться
только одна файловая система, которая не может занимать несколь&shy;ко разделов. В
другой конфигурации диск может состоять только из од&shy;ного раздела, позволяя
создание весьма емких файловых систем.</p> 

<p>Файловая система s5fs занимает раздел диска и состоит из трех основных
компонентов, как показано на рис. 4.1.</p> 

<p><img width=502 height=301
  src="4файловаподсистема.files/image002.jpg" v:shapes="_x0000_i1025"></p> 

<ul>
    <li><i>Суперблок, </i>(superblock). Содержит общую информацию о файловой системе,
     например, об ее архитектуре, общем числе блоков и ин&shy;дексных дескрипторов,
     или метаданных (inode).</li>
 <li><i>Массив индексных дескрипторов </i>(ilist). Содержит метаданные всех файлов
     файловой системы. Индексный дескриптор содержит статус&shy;ную информацию о
     файле и указывает на расположение данных этого файла. Ядро обращается к inode по индексу в массиве ilist. Один inode является корневым (root) inode файловой системы, через него
     обеспечивается доступ к структуре каталогов и файлов после монтирования
     файловой системы. Размер массива ilist является
     фик&shy;сированным и задается при создании файловой системы. Таким об&shy;разом,
     файловая система s5fs имеет ограничение по числу файлов,
     которые могут храниться в ней, независимо от размера этих файлов.</li> 
 <li><i>Блоки хранения данных. </i>Данные обычных
     файлов и каталогов хранят&shy;ся в блоках. Обработка файла осуществляется
     через inode, содержа&shy;щего
     ссылки на блоки данных. Блоки хранения данных занимают большую часть
     дискового раздела, и их число определяет макси&shy;мальный суммарный объем
     файлов данной файловой системы. Раз&shy;мер блока кратен 512 байтам, например
     файловая система S51K SCO UNIX использует
     размер блока в 1 Кбайт (отсюда и название).</li> 
</ul>
<p>Рассмотрим
подробнее каждый из перечисленных компонентов.</p> 

<h3>Суперблок</h3> 

<p>Суперблок&nbsp;&nbsp; содержит&nbsp;&nbsp;
информацию,&nbsp;&nbsp; необходимую&nbsp; для&nbsp;&nbsp;
монтирования&nbsp;&nbsp; и управления
работой файловой системы в целом (например, для размещения новых файлов). В
каждой файловой системе существует только один суперблок, который располагается
в начале раздела. Суперблок считывается в память при монтировании файловой
системы и находится там до ее отключения (размонтирования).</p> 

<p>Суперблок содержит следующую информацию: </p> 

<ul>
 <li>Тип
     файловой системы (s_type)</li> 
 <li>Размер
     файловой системы в логических блоках, включая сам суперблок, ilist и блоки хранения данных (s_fsize)</li> 
 <li>Размер массива
     индексных дескрипторов (s_isize)</li> 
 <li>Число свободных блоков, доступных
     для размещения (s_tfree)</li> 
 <li>Число свободных inode, доступных для размещения (s_tinode)</li> 
 <li>Флаги&nbsp;&nbsp; (флаг&nbsp;&nbsp;
     модификации&nbsp;&nbsp; s_fmod,&nbsp;&nbsp; флаг&nbsp;&nbsp;
     режима&nbsp;&nbsp; монтировани s_fronly)</li> 
 <li>Размер логического блока (512, 1024, 2048) </li> 
 <li>Список номеров свободных inode</li> 
 <li>Список адресов свободных блоков</li> 
</ul> 

<p>Поскольку число свободных inode и блоков хранения данных может быть
значительным, хранение двух последних списков целиком в суперблоке
непрактично.&nbsp; Например, для&nbsp; индексных дескрипторов хранится только часть
списка. Когда число свободных inode в этом списке приближается к 0, ядро просматривает ilist и вновь формирует список свободных inode. Для этого ядро анализирует поле di_mode индексного дескриптора, которое равно 0 у свободных inode.</p> 

<p>К сожалению, такой подход неприменим в отношении свободных блоков
хранения данных, поскольку по содержимому блока нельзя определить свободен он
или нет. Поэтому необходимо хранить список адресов свободных блоков целиком.
Список адресов свободных блоков может занимать несколько блоков хранения
данных, но суперблок содержит только один блок этого списка. Первый элемент
этого блока указывает на блок, хранящий продолжение списка и т. д., как это
показано на рис. 4.1.</p> 

<p>Выделение свободных блоков для размещения файла
производится с конца списка суперблока. Когда в списке остается единственный
элемент, ядро интерпретирует его как указатель на блок, содержащий продолжение
списка. В этом случае содержимое этого блока считывается в суперблок и блок
становится свободным. Такой подход позволяет использовать дисковое про&shy;странство
под списки,&nbsp; пропорциональное
свободному&nbsp; месту&nbsp; в файловое системе. Другими словами, когда
свободного места практически не остается список адресов свободных блоков целиком
помещается в суперблоке.</p> 

<h3>Индексные дескрипторы</h3>
<h3> 

</h3>
<p>Индексный дескриптор, или inode, содержит информацию о файле, необходимую
для обработки данных, т. е. <i>метаданные </i>файла. Каждый файл ассоциирован с
одним inode, хотя может
иметь несколько имен в файловой системе, каждое из которых указывает на один и
тот же inode.</p> 

<p>Индексный дескриптор не содержит:</p> 

<ul>
 <li>имени
     файла, которое содержится в блоках хранения данных ката;</li> 
 <li>содержимого
     файла, которое размещено в блоках хранения данных.</li> 
</ul> 

<p>При открытии файла ядро помещает копию дискового inode в память в <i>таблицу in-core inode, </i>которая содержит несколько дополнительных полей. Структура
дискового inode
(struct&nbsp;&nbsp; dinode) приведена на рис. 4.2 Основные поля
дискового inode
следующие:</p> 

<table class=MsoNormalTable cellspacing=0
 style='margin-left:.7pt;border-collapse:collapse;mso-padding-alt:0cm 5.4pt 0cm 5.4pt' bordercolordark="white" bordercolorlight="black" cellpadding="0">
 <tr style='height:21.65pt'>
  <td width=138 valign=top style='width:103.7pt;padding:0cm 5.4pt 0cm 5.4pt;
  height:21.65pt'>
  <p>di_mode</p> 
  </td> 
  <td width=499 style='width:374.15pt;padding:0cm 5.4pt 0cm 5.4pt;height:21.65pt'>
  <p>Тип файла, дополнительные атрибуты выполнения и права доступа.</p> 
  </td> 
 </tr> 
 <tr> 
  <td width=138 valign=top style='width:103.7pt;padding:0cm 5.4pt 0cm 5.4pt'>
  <p>di_nlinks</p> 
  </td> 
  <td width=499 style='width:374.15pt;padding:0cm 5.4pt 0cm 5.4pt'>
  <p>Число ссылок на файл, т.
  е. количество имен, которые имеет файл в файловой системе.</p> 
  </td> 
 </tr> 
 <tr style='height:24.6pt'>
  <td width=138 valign=top style='width:103.7pt;padding:0cm 5.4pt 0cm 5.4pt;
  height:24.6pt'>
  <p>di_uid,&nbsp;&nbsp; di_gid</p> 
  </td> 
  <td width=499 style='width:374.15pt;padding:0cm 5.4pt 0cm 5.4pt;height:24.6pt'>
  <p>Идентификаторы&nbsp;&nbsp;&nbsp; владельца-пользователя&nbsp;&nbsp;&nbsp; и владельца-группы.</p> 
  </td> 
 </tr> 
 <tr style='height:27.05pt'>
  <td width=138 valign=top style='width:103.7pt;padding:0cm 5.4pt 0cm 5.4pt;
  height:27.05pt'>
  <p>di_size</p> 
  </td> 
  <td width=499 style='width:374.15pt;padding:0cm 5.4pt 0cm 5.4pt;height:27.05pt'>
  <p>Размер
  файла в байтах. Для специальных файлов это поле содержит старший и младший номера
  устройства. </p> 
  </td> 
 </tr> 
 <tr style='height:24.6pt'>
  <td width=138 valign=top style='width:103.7pt;padding:0cm 5.4pt 0cm 5.4pt;
  height:24.6pt'>
  <p>di_atime</p> 
  </td> 
  <td width=499 style='width:374.15pt;padding:0cm 5.4pt 0cm 5.4pt;height:24.6pt'>
  <p>Время
  последнего доступа к файлу.</p> 
  <p>&nbsp;</p> 
  </td> 
 </tr> 
 <tr style='height:24.6pt'>
  <td width=138 valign=top style='width:103.7pt;padding:0cm 5.4pt 0cm 5.4pt;
  height:24.6pt'>
  <p>di_mtime</p> 
  </td> 
  <td width=499 style='width:374.15pt;padding:0cm 5.4pt 0cm 5.4pt;height:24.6pt'>
  <p>Время последней
  модификации.</p> 
  </td> 
 </tr> 
 <tr style='height:24.6pt'>
  <td width=138 valign=top style='width:103.7pt;padding:0cm 5.4pt 0cm 5.4pt;
  height:24.6pt'>
  <p>di_ctime</p> 
  </td> 
  <td width=499 style='width:374.15pt;padding:0cm 5.4pt 0cm 5.4pt;height:24.6pt'>
  <p>Время последней модификации inode (кроме модификации полей di_atime, dijntime).</p> 
  </td> 
 </tr> 
 <tr style='mso-yfti-lastrow:yes;height:24.6pt'>
  <td width=138 valign=top style='width:103.7pt;padding:0cm 5.4pt 0cm 5.4pt;
  height:24.6pt'>
  <p>di_addr[13]</p> 
  </td> 
  <td width=499 style='width:374.15pt;padding:0cm 5.4pt 0cm 5.4pt;height:24.6pt'>
  <p>Массив адресов дисковых блоков хранения
  данных.</p> 
  </td> 
 </tr> 
</table> 

<p>&nbsp;<!--[if gte vml 1]><v:shape 
   id="_x0000_i1026" type="#_x0000_t75" style='width:384pt;height:363.75pt'>
   <v:imagedata src="4файловаподсистема.files/image003.png" o:title=""/>
  </v:shape><![endif]--><![if !vml]><img width=512 height=485
  src="4файловаподсистема.files/image004.jpg" v:shapes="_x0000_i1026"><![endif]></p> 

<p>Поле di_mode хранит несколько атрибутов
файла: тип файла (ifreg для обычных файлов, ifdir для каталогов, ifblk или ifchr для специальных файлов блочных и символьных устройств
соответственно); права доступа к файлу для трех классов пользователей и
дополнительные атрибуты выполнения<b>, </b>SGID
и sticky bit), значения этих атрибутов были подробно
рассмотрены в главе 1.</p> 

<p>Заметим, что в индексном дескрипторе отсутствует информация
о времени создания файла. Вместо этого inode хранит три значения времени последнего
доступа (di_atime), время последней модификации содержимого
файла&nbsp; (di_mtime)&nbsp;&nbsp; и&nbsp;&nbsp; время&nbsp;&nbsp;
последней&nbsp;&nbsp; модификации&nbsp; метаданных файла (di_ctime). В последнем случае не учитываются модификации полей&nbsp;&nbsp; di_atime и di_mtime. Таким образом, di_ctime изменяется, когда изменяется размер файла, владелец,
группа, или число связей.</p> 

<p>Индексный дескриптор содержит информацию о расположении
данных<sub> </sub>файла. Поскольку дисковые блоки хранения данных файла в общем
случае располагаются не последовательно, inode должен хранить физические адреса всех
блоков, принадлежащих данному файлу<sup>1</sup>. В индексном дескрипторе эта
информация хранится в виде массива, каждый элемент которого содержит физический
адрес дискового блока, а индексом массива является номер логического блока
файла. Массив имеет фиксированный размер и состоит из 13 элементов. При этом
первые 10 элементов адресуют непосредственно блоки хранения данных файла.
Одиннадцатый элемент адре&shy;сует блок, в свою очередь содержащий адреса блоков хранения
данных. Двенадцатый элемент указывает на дисковый блок, также хранящий адре&shy;са
блоков,&nbsp; каждый из который&nbsp; адресует блок хранения данных файла. И,
наконец, тринадцатый элемент используется для тройной косвенной адресации,
когда для нахождения адреса блока хранения данных файла используются три
дополнительных блока.</p> 

<p>Такой&nbsp; подход&nbsp; позволяет&nbsp;
при&nbsp; относительно&nbsp;&nbsp; небольшом&nbsp;
фиксированном размере индексного дескриптора поддерживать работу с
файлами, размер которых может изменяться от нескольких байтов до десятка
мегабайт. Для относительно небольших файлов (до 10 Кбайт при размере блока 1024
байтов) используется прямая индексация, обеспечивающая максимальную
производительность. Для файлов, размер которых не превышает 266 Кбайт (10 Кбайт
+ 256x1024), достаточно
простой косвенной адресации. Наконец, при использовании тройной косвенной
адресации можно обеспечить доступ к 16777216 блокам (256x256x256).</p> 

<p>Файлы в UNIX могут содержать так называемые <i>дыры. </i>Например, может
создать пустой файл, с помощью системного вызова <i>lseek(2) </i>сместить файловый указатель относительно начала файла и записать
данные. При этом между
началом файла и началом записанных данных образуется дыра – незаполненная
область. При чтении этой области процесс получит обнуленные байты. Поскольку логические
блоки, соответствующие дыре, не содержат данные, не имеет смысла размещать для них
дисковые блоки. В этом случае
соответствующие элементы массива адресов inode содержат нулевой указатель.
Когда процесс производит чтение такого блока, ядро возвращает
последовательность нулей. Дисковые блоки размещаются только при записи в соответствующие логические блоки
файла<sup>2</sup>.</p> 

<p>1 Размещение данных файла&nbsp;
в произвольно&nbsp; расположенных
дисковых блоках позволяет эффективно использовать дисковое пространство,&nbsp; поскольку ядро может использовать любой
свободный дисковый блок для размещения данных. Однако в файловой системе s5fs
блок может использоваться только одним файлом, поэтому последний блок файла
используется, как правило, не полностью. К тому же такой подход с течением
времени приводит к увеличению фрагментации системы, когда данные файла оказываются
произвольно
разбросанными по диску, что, в свою очередь, увеличивает время доступа к файлу
и уменьшает
производительность обмена данными. Единственным способом уменьшения фрагментации файловой
системы является создание полной резервной копии на другом носителе (или в
другой файловой системе) и затем ее восстановлении. При этом запись файлов будет
производиться последовательно без фрагментации.</p> 

<p>2 Отсутствие размещенных дисковых блоков для части файла
может привести к нежелательным результатам. Например, операция записи в
&quot;дыру&quot; может закончиться неудачей из-за дискового
пространства. При копировании файла с дырой, его копия будет занимать больше
фактического места на диске, чем оригинал. Это связано с тем, что при копировании
производится чтение содержимого оригинала, а затем — запись в другой файл. Это, в частности
может привести к тому, что резервная копия файловой системы не сможет быть
обратно распакована, поскольку вместо неразмещенных блоков будет хранить
законные нулевые
байты и, соответственно, занимать больше места.</p> 

<h3>Имена файлов</h3> 

<p>Как мы уже видели, ни метаданные, ни тем более блоки
хранения данных, не содержат имени файла. Имя файла хранится в файлах
специального типа — каталогах. Такой подход позволяет любому файлу, т. е.
фактиче&shy;ским данным, иметь теоретически неограниченное число имен (названий), в
файловой системе. При этом несколько имен файлов будут соответство&shy;вать одним и
тем же метаданным и данным и являться жесткими связями.</p> 

<p>Каталог файловой системы s5fs представляет собой таблицу, каждый эле&shy;мент которой имеет
фиксированный размер в 16 байтов: 2 байта хранят номер индексного дескриптора
файла, а 14 байтов — его имя. Это накла&shy;дывает ограничение на число inode, которое не может превышать 65535. Также
ограничена и длина имени файла: его максимальный размер — 14 символов.
Структура каталога приведена на рис. 4.3.</p> 

<p>Первые два элемента каталога адресуют сам каталог (текущий
каталог) под именем &quot;.&quot; и родительский каталог под именем
&quot;..&quot;.</p> 

<p>&nbsp;При удалении имени файла из каталога (например, с
помощью команды <i>rm(1)</i>)<i>, </i>номер inode соответствующего элемента
устанавливается равным 0. Ядро обычно не удаляет такие свободные элементы,
поэтому размер каталога не уменьшается даже при удалении файлов. Это является
потенциально проблемой для каталогов,&nbsp;
в&nbsp; которые&nbsp; временно было помещено большое количество
файлов. После удаления большинства из них размер каталога останется достаточно
большим, поскольку записи удаленных файлов будут по прежнему существовать.</p> 

<p>&nbsp;Иллюстрацию этого явления в SCO UNIX
можно привести, применив команду <i>hd(lM),
</i>обеспечивающую
вывод неинтерпретированного содержимого файла (шестнаддатеричный дамп).</p> 

<p>&nbsp;<img width=495 height=223
  src="4файловаподсистема.files/image006.jpg" v:shapes="_x0000_i1027"></p> 

<p>Можно заметить, что имен файлов,
расположенных во второй части вывода команды <i>hd(lM) </i>на самом деле не существует — об этом свидетельствуют нулевые
значения номеров inode,
это же подтверждает вывод команды <i>ls(l):</i></p> 

<p><img width=490 height=385
src="4файловаподсистема.files/image008.jpg" v:shapes="_x0000_i1028"></p> 

<h3>Недостатки и ограничения</h3> 

<p>Файловая система s5fs привлекательна благодаря своей простоте.&nbsp; Однако обратной стороной медали является
низкая надежность и производительность.</p> 

<p>&nbsp;С точки зрения надежности слабым местом
этой файловой системы является суперблок. Суперблок несет основную информацию о
файловой системе в целом, и при его повреждении файловая система не может
использоваться. Поскольку в файловой системе s5fs суперблок хранится в единственном варианте, вероятность
возникновения ошибок достаточно велика.</p> 

<p>&nbsp;Относительно низкая производительность
связана с размещением компонентов файловой
системы на диске. Метаданные файлов располагаются в начале файловой системы, а
далее следуют блоки хранения данных. При работе с файлом, происходит обращение
как к его метаданным, так и к дисковым блокам, содержащим его данные. Поскольку
эти структуры дан&shy;ных могут быть значительно разнесены в дисковом пространстве,
необхо&shy;димость постоянного перемещения головки диска увеличивает время дос&shy;тупа
и, как следствие, уменьшает производительность файловой системы в целом. К
этому же эффекту приводит фрагментация файловой системы, поскольку отдельные
блоки файла оказываются разбросанными по всему разделу диска.</p> 

<p>Использование дискового пространства также
не оптимально. Для увели&shy;чения производительности&nbsp; файловой&nbsp;&nbsp;
системы&nbsp; более&nbsp; предпочтительным является использование
блоков больших размеров. Это позволяет считы&shy;вать большее количество данных за
одну операцию ввода/вывода. Так, на-&laquo;мер, в UNIX SVR2 размер блока составлял 512 байтов, а в SVR3 — уже 1024 байтов. Однако поскольку блок
может использоваться только одним файлом, увеличение размера блока приводит к
увеличению неиспользуемого дискового пространства за счет частичного заполнения
последнего блока файла. В среднем для каждого файла теряется половина блока.</p> 

<p>Массив inode имеет фиксированный размер,&nbsp; задаваемый&nbsp;
при создании файловой системы. Этот размер накладывает ограничение на
максимальное число файлов, которые могут существовать в файловой системе.
Расположение границы между метаданными файлов и их данными (блоками хранения
данных) может оказаться неоптимальным, приводящим либо к нехватке inode, если файловая система хранит файлы
небольшого размера, либо к нехватке дисковых блоков для хранения файлов
большого размера. Поскольку динамически изменить эту границу невозможно, всегда останется неиспользованное дисковое пространство либо в массиве inode, либо в блоках хранения данных.</p> 

<p>Наконец ограничения, накладываемые на
длину имени файла (14 символов) и общее максимальное число inode (65535), также являются слишком жесткими.</p> 

<p>Все эти недостатки привели к
разработке&nbsp; новой архитектуры файловой
системы,&nbsp;&nbsp; которая&nbsp;&nbsp; появилась&nbsp;&nbsp;
в&nbsp;&nbsp; версии&nbsp;&nbsp; 4.2BSD&nbsp;&nbsp; UNIX&nbsp;&nbsp;
пол Berkeley Fast File System,
или FSS.</p> 

<h3>Файловая система BSD UNIX</h3> 

<p>В версии 4.3BSD UNIX были внесены существенные улучшения в
архитектуру файловой системы, повышающие как ее производительность, так и
надежность. Новая файловая система получила название Berkeley Fast File System (FFS).</p> 

<p>Файловая система FFS, обладая полной функциональностью системы
использует те же структуры данных ядра. Основные изменения затронули
расположение файловой системы на диске, дисковые структуры данных и алгоритмы
размещения свободных блоков.</p> 

<p>Как и в случае файловой системы s5fs, суперблок содержит общее описание файловой системы и
располагается в начале раздела. Однако в суперблоке не хранятся данные о
свободном пространстве файловой системы, такие как массив свободных блоков и inode. Поэтому данные суперблока остаются
неизменными на протяжении всего времени существования фай&shy;ловой системы.
Поскольку данные суперблока жизненно важны для рабо&shy;ты всей файловой системы,
он дублируется для повышения надежности.</p> 

<p>Организация файловой системы
предусматривает логическое деление дискового раздела на одну или несколько <i>групп
цилиндров </i>(cylinder group).
Группа цилиндров представляет собой несколько последовательных дисковых цилиндров.
Каждая группа цилиндров содержит управляющую информацию, включающую резервную
копию суперблока, массив inode, ные о свободных блоках и итоговую информацию об использовании
дисковых блоков в группе (рис. 4.4).</p> 

<p>&nbsp;<img width=500 height=218
  src="4файловаподсистема.files/image010.jpg" v:shapes="_x0000_i1029"></p> 

<p>Для каждой группы цилиндров
при создании файловой системы выделяется место под определенное количество inode. При этом обычно на каждые 2 Кбайт блоков
хранения данных создается один inode. Поскольку размеры группы цилиндров и массива inode фиксированы, в файловой системе BSD UNIX присутствуют ограничения, аналогичные s5fs.</p> 

<p>Идея такой структуры файловой системы
заключается в создании класте&shy;ров, распределенных по всему разделу, вместо
того, чтобы группировать все inode в начале. Тем самым уменьшается время доступа к данным
конкретного файла, поскольку блоки данных располагаются ближе к адресующим их inode. Такой подход также повышает надежность
файловой системы, уменьшая вероятность потери всех индексных дескрипторов в
результате сбоя.</p> 

<p>Управляющая информация располагается с
различным смещением от начала группы цилиндров. В противном случае, например,
при размещении в начале группы цилиндров, информация всех групп оказалась бы
физиче&shy;ски расположенной на одной пластине диска и могла бы быть уничтожена при
выходе из строя этой пластины. Это смещение выбирается равным одному сектору
относительно предыдущей группы, таким образом для со&shy;седних групп управляющая
информация начинается на различных пласти&shy;нах диска. В этом случае потеря
одного сектора, цилиндра или пластины не приведет к потере всех копий
суперблоков.</p> 

<p>Производительность файловой системы
существенным образом зависит от размера блока хранения данных. Чем больше
размер блока, тем большее количество данных может быть прочитано без поиска и
перемещения дис&shy;ковой головки. Файловая система FFS поддерживает размер блока до 64 Кбайт. Проблема заключается
в том,&nbsp; что типичная&nbsp; файловая&nbsp;
система UNIX<b> </b>состоит из
значительного числа файлов небольшого размера. Это приводит к тому, что
частично занятые блоки используются неэффективно, что может привести к потере
до 60% полезной емкости диска.</p> 

<p>Этот недостаток был преодолен с помощью
возможности фрагментации блока. Каждый блок может быть разбит на два, четыре
или восемь фрагментов. В то время как блок является единицей передачи данных в
операциях вода/вывода,&nbsp; фрагмент
определяет адресуемую единицу хранения данных на диске. Таким образом был
найден компромисс между производительностью ввода/вывода и эффективностью
хранения данных. Размер фрагмента задается при создании файловой системы,&nbsp; его максимальное значение определяется
размером блока (0,5 размера блока), а минимальный – физическими ограничениями
дискового устройства, а именно: минимальной единицей адресации диска&nbsp; – сектором.</p> 

<p>Информация о свободном пространстве в
группе хранится не в виде списка свободных блоков, а в виде <i>битовой карты
блоков. </i>Карта блоков, связанная с определенной группой&nbsp; цилиндров,&nbsp;
описывает свободное пространство в фрагментах, для определения того,
свободен данный блок или нет, ядро анализирует биты фрагментов, составляющих
блок. На рис. 4.5 приведен пример карты свободных блоков и соответствия между
битами карты, фрагментами и блоками группы цилиндров.</p> 

<p>Существенные&nbsp; изменения&nbsp;
затронули&nbsp; алгоритмы&nbsp; размещения&nbsp;
свободных блоков и inode, влияющие на расположение файлов на диске. В файлов системе s5fs используются весьма примитивные правила размещения.
Свободные блоки и inode
просто выбираются из конца соответствующего списка, что со временем приводит,
как уже обсуждалось, к значительному разбросу данных файла по разделу диска.</p> 

<p>В отличие от s5fs, файловая система FFS при размещении блоков использует
стратегию, направленную на увеличение производительности.&nbsp; Некоторые из принципов приведены ниже:</p> 

<ul>
<li>Файл по возможности размещается в блоках
хранения данных, принадлежащих одной группе цилиндров, где расположены его
метаданные. Поскольку многие операции файловой системы включают работу,
связанную как с метаданными, так и с данными файла, это правило уменьшает время
совершения таких операций.</li> 
 <li>Все файлы каталога по возможности размещаются в одной группе цилиндров. Поскольку многие команды работают с несколькими файлами одного и того же каталога,
     данный подход увеличивает скорость последовательного доступа к этим
     файлам.</li> 
 <li>Каждый новый каталог по возможности помещается в группу
     цилиндров, отличную от группы родительского каталога. Таким образом
     достигается равномерное распределение данных по диску.</li> 
 <li>Последовательные блоки размещаются исходя из оптимизации
     физического доступа. Дело в том, что существует определенный проме&shy;жуток
     времени между моментом завершения чтения блока и началом чтения
     следующего. За это время диск успеет совершить оборот на некоторый угол.
     Таким образом, следующий блок должен по воз&shy;можности располагаться с
     пропуском нескольких секторов. В этом случае при чтении последовательных
     блоков не потребуется совер&shy;шать &quot;холостые&quot; обороты диска.</li> 
</ul> 

<p>Таким образом, правила
размещения свободных блоков, с одной стороны, направлены на уменьшение времени
перемещения головки диска, т. е. на локализацию данных в одной группе
цилиндров, а с другой — на равно&shy;мерное распределение данных по диску. От
разумного баланса между эти&shy;ми двумя механизмами зависит, в конечном итоге,
производительность файловой системы. Например, в предельном варианте, когда все
данные локализованы в одной большой группе цилиндров, мы получаем типичную
файловую систему s5fs.</p> 

<p>Описанная архитектура является весьма эффективной с точки зрения
на&shy;дежности и производительности. К сожалению, эти параметры файловой системы FSS начинают значительно ухудшаться по мере
уменьшения сво&shy;бодного места. В этом случае системе не удается следовать
вышеприведенным правилам и размещение блоков далеко от оптимального. Практика
показывает, что FSS
имеет удовлетворительные характеристики при нали&shy;чии более 10% свободного
места.</p> 

<h3>Каталоги</h3> 

<p>Структура каталога
файловой системы FFS была изменена для поддержки длинных имен файлов (до 255 символов). Вместо записей
фиксированной длины запись каталога FFS
представлена структурой, имеющей следующие поля:</p> 

<table class=MsoNormalTable border=0 cellspacing=0 cellpadding=0
 style='margin-left:1.45pt;border-collapse:collapse;mso-padding-alt:0cm 5.4pt 0cm 5.4pt'>
 <tr style='height:18.4pt'>
  <td width=161 style='width:120.95pt;padding:0cm 5.4pt 0cm 5.4pt;height:18.4pt'>
  <p>d_ino</p> 
  </td> 
  <td width=475 style='width:356.15pt;padding:0cm 5.4pt 0cm 5.4pt;height:18.4pt'>
  <p>Номер inode (индекс в массив ilist)</p> 
  </td> 
 </tr> 
 <tr style='height:18.85pt'>
  <td width=161 style='width:120.95pt;padding:0cm 5.4pt 0cm 5.4pt;height:18.85pt'>
  <p>d_reclen</p> 
  </td> 
  <td width=475 style='width:356.15pt;padding:0cm 5.4pt 0cm 5.4pt;height:18.85pt'>
  <p>Длина
  записи</p> 
  </td> 
 </tr> 
 <tr style='height:17.3pt'>
  <td width=161 style='width:120.95pt;padding:0cm 5.4pt 0cm 5.4pt;height:17.3pt'>
  <p>d_namlen</p> 
  </td> 
  <td width=475 style='width:356.15pt;padding:0cm 5.4pt 0cm 5.4pt;height:17.3pt'>
  <p>Длина имени файла</p> 
  </td> 
 </tr> 
 <tr style='mso-yfti-lastrow:yes;height:17.75pt'>
  <td width=161 style='width:120.95pt;padding:0cm 5.4pt 0cm 5.4pt;height:17.75pt'>
  <p>d_name[]</p> 
  </td> 
  <td width=475 style='width:356.15pt;padding:0cm 5.4pt 0cm 5.4pt;height:17.75pt'>
  <p>Имя &nbsp;файла</p> 
  </td> 
 </tr> 
</table> 

<p>&nbsp;Имя
файла имеет переменную длину, дополненную нулями до 4-байтной границы. При
удалении имени файла принадлежавшая ему запись присоединяется к предыдущей, и значение поля&nbsp; d_reclen увеличивается на соответствующую величину. Удаление первой записи
выражается в присвоении нулевого
значения полю d_ino. Структура каталога файловой системы FFS
приведена на рис. 4.6.</p> 

<p>&nbsp;<img width=496 height=496
  src="4файловаподсистема.files/image014.jpg" v:shapes="_x0000_i1031"></p> 

<p><b>Архитектура
виртуальной файловой системы</b></p> 

<p>Как было показано, различные
типы файловых систем существенно отличаются по внутренней архитектуре. В то же
время современные версии UNIX обеспечивают одновременную работу с несколькими типами файловых
систем.&nbsp; Среди&nbsp; них можно выделить локальные файловые&nbsp; системы различной архитектуры, удаленные и
даже отличные от файловой системы UNIX, например DOS. Такое сосуществование обеспечивается путем разделения каждой
файловой системы на <i>зависимый </i>и <i>независимый </i>от реализации уровни, последний из которых является общим и
представляет для остальных подсистем
ядра некоторую абстрактную файловую систему. Независимый уровень также называется <i>виртуальной файловой
системой </i>(рис. 4.7). При этом
дополнительные файловые системы различных типов могут быть встроены в
ядро UNIX подобно тому, как
это происходит с драйверами устройств.</p> 

<p><img width=523 height=414
src="4файловаподсистема.files/image016.jpg" v:shapes="_x0000_i1032"></p> 

<p>&nbsp;<b>Виртуальные
индексные дескрипторы</b></p> 

<p>Дисковый файл обычно имеет связанную с ним структуру
данных, называемую метаданными или inode,
где хранятся основные характеристики данного файла и с помощью которой
обеспечивается доступ к его данным. Одним из исключений из этого правила
является файловая система DOS, в которой
структуры файла и его метаданных существенно отличаются от принятых в UNIX. Тем не менее виртуальная файловая система основана
представлении метаданных файла в виде, сходном с традиционной семантикой UNIX.&nbsp;&nbsp; Интерфейсом
работы с файлами является vnode (от virtual node —
виртуальный индексный дескриптор).</p> 

<p>&nbsp;Первоначально этот интерфейс
был разработан в&nbsp;&nbsp; 1984 году фирмой Sun Microsystems для обеспечения требуемой унификации работы с
файловыми системами различных типов, в частности, с NFS и ufs (FFS). Сегодня виртуальная
файловая система является стандартом в SVR4, хотя ряд других версий UNIX<b> </b>также
реализуют подобную архитектуру (например, независимая файловая система SCO UNIX)<b>.</b></p> 

<p>Метаданные всех активных
файлов (файлов, на которые ссылаются один или более процессов) представлены в
памяти в виде in-core mode, в качестве которых в
виртуальной файловой системе выступают vnode. Структура данных vnode
одинакова для всех файлов, независимо от типа peaльной файловой системы, где
фактически располагается файл. Данные vnode содержат информацию,
необходимую для работы виртуальной файловой темы, а также неизменные
характеристики файла, например, такие как тип файла.</p> 

<p>Основные поля vnode
приведены в табл. 4.1.</p> 

<div style='mso-element:frame;mso-element-frame-height:8.0cm;mso-element-frame-hspace:
1.8pt;mso-element-frame-vspace:2.9pt;mso-element-wrap:no-wrap-beside;
mso-element-anchor-vertical:paragraph;mso-element-anchor-horizontal:margin;
mso-element-left:-9

<table cellspacing=0 cellpadding=0 hspace=0 vspace=0 height=310>
 <tr> 
  <td valign=top align=left height=310 style=' padding-top:2.9pt;padding-right:
  1.8pt;padding-bottom:2.9pt;padding-left:1.8pt'>
  <p><img width=508 height=302
  src="4файловаподсистема.files/image018.jpg" v:shapes="_x0000_i1033"></p> 
</div> 

<p>Каждый vnode содержит число ссылок v_count,&nbsp; которое увеличивается при
открытии процессом файла и уменьшается при его закрытии. Когда число&nbsp; ссылок становится равным нулю,&nbsp;&nbsp;&nbsp; вызывается операция vn_inactive(),&nbsp; которая сообщает реальной файловой системе,
что на vnode никто больше не ссылается. После этого файловая система может
освободить vnode (и, например, соответствующий ему inode)
или поместить его в кэш для дальнейшего использования.</p> 

<p>Поле v_vfsp указывает на файловую систему
(структуру vfs, о которой мы поговорим в
следующем разделе), в которой расположен файл, адресованный
данным vnode. Если vnode является точкой монтирования, то поле&nbsp; v_vfsmountedhere&nbsp; указывает&nbsp;&nbsp;
на&nbsp;&nbsp; подключенную&nbsp;&nbsp; файловую&nbsp;&nbsp;
систему, “перекрывающую” данный vnode. </p> 

<p>Поле v_data
указывает
на данные, относящиеся к конкретной реализации реальной файловой системы.
Например, для дисковой файловой системы ufs, v_data указывает на запись в таблице in-core inode.</p> 

<p>&nbsp;Набор
операций&nbsp; над vnode указан&nbsp;
полем&nbsp; v_op.&nbsp;&nbsp; В&nbsp;
терминах объектно-ориентированного программирования этот набор
представляет собой виртуальные методы класса vnode. Он является своего рода шлюзом к реальной файловой системе, позволяя
предоставить общий интерфейс виртуальной файловой системы и в то же время
обеспечить специфические реализации функций работы с файлами, необходимые для
различных типов файловых систем. Некоторые операции, большинство из которых уже
знакомы читателю по системным вызовам, приведены в табл. 4.2.</p> 

<p>&nbsp;<img width=503 height=231
  src="4файловаподсистема.files/image020.jpg" v:shapes="_x0000_i1034"></p> 

<p><img width=502 height=468
src="4файловаподсистема.files/image022.jpg" v:shapes="_x0000_i1035"></p> 

<p>&nbsp;Взаимосвязь между
независимыми дескрипторами (vnode) и зависимыми от реализации
метаданными файла показана на рис. 4.8.</p> 

<p>&nbsp;<img width=495 height=367
  src="4файловаподсистема.files/image024.jpg" v:shapes="_x0000_i1036"></p> 

<p><b>Монтирование
файловой системы</b></p> 

<p>Прежде чем может состояться работа с файлами,
соответствующая файловая система должна быть встроена в существующее
иерархическое дерево.</p> 

<p>Только после этого ядро сможет выполнять файловые
операции, такие как создание, открытие, чтение или запись в файл. Эта операция
встраивания получила название <i>подключения </i>или <i>монтирования файловой
системы. </i></p>
<p>Каждая подключенная&nbsp;
файловая система&nbsp;
представлена&nbsp; на&nbsp; независимом уровне в виде структуры vfs,
аналоге записи таблицы монтирования дисковой
файловой системы. Структуры vfs всех
подключенных файловых систем организованы в виде односвязного списка, в совокупности обеспечивая
информацию, необходимую для обслуживания
всего иерархического дерева, а также информацию о реальной файловой системе, которые не изменяются на протяжении работы. Первой записью списка
всегда является корневая файловая система. В дальнейшем, список vfs мы
будем называть устоявшимся термином – таблица монтирования. Поля структуры vfs приведены в табл. 4.3.</p> 

<p>&nbsp;<img width=506 height=218
src="4файловаподсистема.files/image026.jpg" v:shapes="_x0000_i1037"></p> 

<p>Поле vfs_data содержит
указатель на данные реальной файловой системы. Например, для дисковой файловой
системы s5fs, это поле
указывает на суперблок, размещенный в памяти.</p> 

<p>Поле vfs_op указывает на операции
файловой системы, которые в терминах оъектно-ориентированного подхода могут
быть названы виртуальными методами объекта vfs.
Возможные операции файловой системы приведены в табл. 4.4. Поскольку они существенным образом зависят от
архитектуры и конкретно реализации, поля vfs_op заполняются указателями на соответствующие функции реальной файловой системы при ее
монтировании.</p> 

<p><img width=513 height=141
src="4файловаподсистема.files/image028.jpg" v:shapes="_x0000_i1038"></p> 

<div style='mso-element:frame;mso-element-frame-height:180.0pt;mso-element-frame-hspace:
1.8pt;mso-element-frame-vspace:2.9pt;mso-element-wrap:no-wrap-beside;
mso-element-anchor-vertical:paragraph;mso-element-anchor-horizontal:margin;
mso-element-left:

<table cellspacing=0 cellpadding=0 hspace=0 vspace=0 height=248>
 <tr> 
  <td valign=top align=left height=248 style=' padding-top:2.9pt;padding-right:
  1.8pt;padding-bottom:2.9pt;padding-left:1.8pt'>
  <p><img width=502 height=240
  src="4файловаподсистема.files/image030.jpg" v:shapes="_x0000_i1039"></p> 
</div> 

<p>Для инициализации и
монтирования реальной файловой системы UNIX хранит <i style='mso-bidi-font-style:
normal'>коммутатор файловых систем</i>&nbsp; (File&nbsp;&nbsp; System&nbsp; Switch),&nbsp; адресующий процедурный интерфейс для каждого
типа файловой системы, поддерживаемой ядром. UNIX System V для
этого использует глобальную таблицн, каждый&nbsp;&nbsp;
элемент&nbsp;&nbsp; которой&nbsp;&nbsp; соответствует&nbsp;&nbsp; определенному&nbsp;&nbsp; типу&nbsp;
реальной файловой системы,&nbsp;
например s5fs,&nbsp; ufs или&nbsp; nfs.&nbsp; Элемент этой таблицы vfssw
имеет поля, указанные в табл. 4.5.</p> 

<p><img width=496 height=119
src="4файловаподсистема.files/image032.jpg" v:shapes="_x0000_i1040"></p> 

<p>Взаимодействие&nbsp; структур&nbsp;
виртуальной&nbsp; файловой&nbsp; системы&nbsp;
показано на рис. 4.9.</p> 

<p>Монтирование&nbsp;&nbsp; файловой&nbsp;&nbsp;
системы&nbsp;&nbsp; производится&nbsp;&nbsp; системным вызовом <i 
style='mso-bidi-font-style:normal'>mount(2).</i> В качестве аргументов передаются тип монтируемой файловой системы, имя
каталога, к которому подключается файловая система <i>(точка монтирования)</i>, флаги (например, доступ к файловой
системе только для чтения) и дополнительные данные, конкретный вид и
содержимое&nbsp; которых зависят от реализации
реальной файловой системы. При этом производится&nbsp; поиск vnode,&nbsp;&nbsp; соответствующего&nbsp; файлу – точке&nbsp;
монтирования (операция lookup()&nbsp; или namei() трансляции имени), и
проверяется, что файл является каталогом и не используется в настоящее время
для монтирования других файловых систем.</p> 

<p>Затем происходит поиск
элемента коммутатора файловых систем vfssw[], соответствующего типу
монтируемой файловой системы. Если такой элемент найден, вызывается операция инициализации, адресованная
полем vsw_init(). При этом
выполняется размещение специфических для данного типа файловой системы данных,
после чего ядро размещает структуру vfs и помещает ее в связанный список подключенных
файловых систем, как это показано&nbsp; на
рис. 4.11.&nbsp;&nbsp; Поле&nbsp;&nbsp; vfs_vnodecovered
указывает&nbsp; на vnode точки монтирования. Это поле устанавливается нулевым для корневой (root)
файловой системы, элемент vfs&nbsp; которой всегда расположен первым в списке
подключенных файловых систем. Поле vfs_op адресует вектор операций, определенный для данного типа файловой
системы. Наконец, указатель&nbsp;&nbsp;&nbsp; на&nbsp;&nbsp;&nbsp; данный&nbsp;&nbsp;&nbsp;
элемент&nbsp;&nbsp;&nbsp; vfs&nbsp;&nbsp;&nbsp; сохраняется&nbsp;&nbsp;&nbsp; в поле v_vfsmountedhere
виртуального индексного дескриптора
каталога – точки монтирования.</p> 

<p><img width=503 height=302
src="4файловаподсистема.files/image034.jpg" v:shapes="_x0000_i1041"></p> 

<p>После этого вызывается операция vfs_mount(),
соответствующая данному типу файловой системы. Конкретные действия определяются реализацией файловой&nbsp;
системы&nbsp; и&nbsp;&nbsp; могут&nbsp;
существенно&nbsp; различаться.&nbsp;&nbsp; Например, операция монтирования локальной
файловой системы ufs предусматривает считывание в память метаданных системы,
таких как суперблок, в то время как монтирование удаленной NFS файловой системы включает передачу сетевого запроса
файловому серверу. Однако монтирование предусматривает выполнение и ряда общих операций,
включающих:</p> 

<ul>
 <li>проверку соответствующих прав на выполнение
     монтирования;</li> 
 <li>размещение и
     инициализацию специфических для файловой системы данного типа данных,
     сохранение адреса этих данных в поле vfs_data
     элемента vfs;</li> 
 <li>размещение
     vnode для корневого каталога подключаемой файловой
     системы, доступ к которому осуществляется с помощью операции vfs_root().</li> 
</ul> 

<p>После подключения файловая система может быть
адресована по имени точки монтирования. В частности, при отключении файловой системы
с помощью системного вызова <i 
style='mso-bidi-font-style:normal'>umount(2)</i>, в качестве аргумента ему передается имя точки
монтирования. Адресация с помощью специального устройства, как это происходило
раньше, нарушает унифицированный вид виртуальной файловой системы, так как
некоторые типы вообще не имеют такого устройства (например, NFS).</p> 

<p>Определение корневого vnode для подключенной файловой системы производится с
помощью операции vfs_root(). Заметим, что в некоторых реализациях независимой
файловой системы (например, в SCO UNIX, хотя там используется другая терминология) одно из
полей записи таблицы монтирования явно указывало на корневой vnode. Подход, предложеный фирмой Sun Microsystems,
позволяет не хранить корневой vnode постоянно,
размещая его только при необходимости работы с файловой системой. Это
минимизирует ресурсы, занимаемые подключенными файловыми сис&shy;темами, которые
продолжительное время не используются.</p> 

<p>На рис. 4.10 приведен вид логического файлового дерева
до и после монтирования файловой системы А к каталогу /usr/local. На рис.
4.11 приведен вид виртуальной файловой системы после этой операции
монтирования.</p> 

<p>Исследовать описанные&nbsp;
структуры данных&nbsp; можно&nbsp; с&nbsp;
помощью утилиты <i 
style='mso-bidi-font-style:normal'>crash(lM)</i>. Для этого применяются команды <i 
style='mso-bidi-font-style:normal'>vfs</i> и <i 
style='mso-bidi-font-style:normal'>vnode</i>, отображающие
содержимое соответствующих структур данных. Приведем пример такого исследования
файлового дерева операционной системы Solaris2.5:</p> 

<p><img width=502 height=250
src="4файловаподсистема.files/image036.jpg" v:shapes="_x0000_i1042"></p> 

<p><img width=368 height=544
src="4файловаподсистема.files/image038.jpg" v:shapes="_x0000_i1043"></p> 

<div style='mso-element:frame;mso-element-frame-height:291.2pt;mso-element-frame-hspace:
1.8pt;mso-element-frame-vspace:2.9pt;mso-element-wrap:no-wrap-beside;
mso-element-anchor-vertical:paragraph;mso-element-anchor-horizontal:margin;
mso-element-left:

<table cellspacing=0 cellpadding=0 hspace=0 vspace=0 height=396>
 <tr> 
  <td valign=top align=left height=396 style=' padding-top:2.9pt;padding-right:
  1.8pt;padding-bottom:2.9pt;padding-left:1.8pt'>
  <p><img width=515 height=388
  src="4файловаподсистема.files/image040.jpg" v:shapes="_x0000_i1044"></p> 
</div> 

<p>Мы&nbsp;&nbsp;
распечатали&nbsp;&nbsp; список&nbsp;&nbsp; подключенных&nbsp;&nbsp; файловых&nbsp;&nbsp;
систем&nbsp;&nbsp; (коман <i>mount(lM)</i>) и элементы vfs
таблицы монтирования. Рассмотрим подробнее vnode точки монтирования файловой системы
раздела <b>/dev/dsk/c0t0d0s.</b></p> 

<p>&nbsp;<img width=512 height=45
  src="4файловаподсистема.files/image042.jpg" v:shapes="_x0000_i1045"></p> 

<p>Удостоверимся, что поле v_vfsmountedhere (VFSMNTED) адресует элемент vfs
подключенной файловой системы, а поле v_fsp (vfsp) указывает на элемент корневой
файловой системы.</p> 

<p><img width=507 height=79
  src="4файловаподсистема.files/image044.jpg" v:shapes="_x0000_i1046"></p>
<p>Наконец, посмотрим на
содержимое inode файловой системы ufs, адресованного полем v_data (VDATA)
виртуального индексного дескриптора.</p> 

<p><img width=497 height=55
  src="4файловаподсистема.files/image046.jpg" v:shapes="_x0000_i1047"></p> 

<p>Полученная информация
показывает, что запись таблицы inode ufs
адресует дисковый индексный дескриптор с номером 7552 (INUMB). Для того чтобы узнать имя
файла, используем команду ncheck(1M):</p> 

<p>&gt; !ncheck –i 7552</p> 

<p>/dev/dsk/c0t3d0s0:</p> 

<p>7552 /usr/local</p> 

<h3>Трансляция имен</h3> 

<p>Прикладные процессы, запрашивая услуги
файловой системы, обычно имеют дело с именем файла или файловым дескриптором, полученным
в результате определенных системных вызовов. Однако ядро системы для обеспечения работы с
файлами использует не имена, а индексные деск&shy;рипторы. Таким образом,
необходима трансляция имени файла, переда&shy;ваемого, например, в качестве аргумента системному
вызову <i>ореп(2), </i>в но&shy;мер соответствующего vnode.</p> 

<p>В табл. 4.6 приведены
системные вызовы, для выполнения которых требу&shy;ется трансляция имени файла.</p> 

<p><img width=498 height=238
src="4файловаподсистема.files/image048.jpg" v:shapes="_x0000_i1048"></p>
<p>Говоря формально, полное имя файла представляет собой
последователь&shy;ность слов, разделенных символом '/'. Каждый компонент имени,
кроме собственного является именем каталога. Последний компонент определяет
собственное имя файла. При этом
полное имя может быть абсолютным или
относительным. Если полное имя начинается с символа
'/', представляющего корневой каталог общего логического дерева файловой
системы, то оно является абсолютным, однозначно определяющим файл из любого
места файловой системы. В противном случае, имя является относительным и
адресует файл относительно текущего каталога. Примером относительного
имени&nbsp; может служить include/sys/user.h, а абсолютное имя этого файла – /usr/include/sys/user.h. Как следует из этих рассуждений, два каталога играют ключевую роль
при трансляции имени: корневой каталог и текущий каталог. Каждый процесс
адресует эти каталоги двумя полями структуры u_area:</p> 

<p>struct vnode *u_cdir&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Указатель на vnode текущего каталога</p> 

<p>struct vnode *u_rdir&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Указатель на vnode корневого каталога</p> 

<p>В зависимости
от имени файла трансляция начинается с vnode, адресованного либо полем u_cdir,
либо u_rdir. Трансляция имени осуществляется покомпонентно, при
этом для vnode текущего каталога вызываете соответствующая ему
операция vn_lookup(), в качестве аргумента
которой передается имя следующего компонента. В результате операции
возвращается vnode, соответствующий искомому компоненту.</p> 

<p>Если&nbsp;&nbsp; для&nbsp;&nbsp; vnode&nbsp;&nbsp; каталога&nbsp;&nbsp;
установлен&nbsp;&nbsp; указатель&nbsp;&nbsp; vn_vfsmountedhere, то&nbsp; данный&nbsp;&nbsp;
каталог&nbsp; является&nbsp;&nbsp; точкой&nbsp;&nbsp;
монтирования.&nbsp;&nbsp; Если&nbsp;&nbsp; имя файла требует дальнейшего спуска по
дереву файловой системы (т. е. пересечения точки монтирования), то операция vn_lookup()&nbsp;&nbsp; следует указателю vn_vfsmountedhere для перехода в подключенную
файловую систем и вызывает для&nbsp; нее&nbsp; операцию&nbsp;
vfs_root() для&nbsp;
получения ее корневого vnode. Трансляция имени затем
продолжается с этого места.</p> 

<p>Пересечение границы файловых
систем возможно и при восхождении по дереву, например, если имя файла задано
указанием родительского каталога – ../../myfile.txt. Если при движении в этом направлении по пути
встречается корневой vnode подключенной файловой системы
(установлен флаг VROOT в поле v_flag), то операция vn_lookup()
следует указателю vfs_vnodecovered, расположенному в записи vfs этой
файловой системы. При этом происходит пересечение границы файловых систем, и
дальнейшая трансляция продолжается с точки монтирования.</p> 

<p>Если искомый файл является
символической связью, и системный вызов от имени которого происходит трансляция
имени, &quot;следует&quot; символической связи, операция vn_lookup()
вызывает vn_readlink() для получения имени
целевого файла. Если оно является абсолютным (т.е. начинается с &quot;/&quot;),
то трансляция начинается с vnode корневого каталога,
адресованного полем u_rdir области и_агеа.</p> 

<p>Процесс трансляции имени
продолжается, пока не просмотрены все компоненты имени или не обнаружена ошибка
(например, отсутствие прав доступа).&nbsp;
В&nbsp; случае&nbsp; удачного&nbsp;
завершения&nbsp; возвращается vnode
файла.</p> 

<h3>Доступ к файловой системе</h3> 

<p>Как было показано в главе 2,
процесс совершает операции с файлами, адресуя их при помощи файловых
дескрипторов – целых чисел, имеющих локальное для процесса значение. Это
значит, что файловый дескриптор одного процесса может адресовать совершенно
другой файл, нежели файловый дескриптор с таким же номером, используемый другим
процессом. Процесс получает файловый дескриптор с помощью ряда системных вызовов,
например, open(2) или create(2), выполняющих операцию
трансляции имени, в результате которой выделяемый файловый дескриптор адресует
определенный inode (или vnode) и, соответственно, файл
файловой системы.</p> 

<p>На рис. 4.12 показаны
основные структуры ядра, необходимые для доступа к файлу.</p> 

<p><img width=498 height=315
src="4файловаподсистема.files/image050.jpg" v:shapes="_x0000_i1049"></p> 

<p>Файловый дескриптор,
используемый для доступа процесса к файлу, является индексом таблицы файловых
дескрипторов (file descriptor table).
Каждый процесс имеет собственную таблицу файловых дескрипторов, которая
расположена в его u-area. На рис. 4.12 показаны два
процесса, каждый из которых использует таблицу файловых дескрипторов.</p> 

<p>Каждая активная запись этой
таблицы, представляющая открытый файл, адресует запись системной файловой
таблицы (system file table),
в которой хранятся такие параметры, как режим доступа к файлу (запись, чтение,
добавление и т.д.), текущее смещение в файле (файловый указатель), а также
указатель на vnode этого файла. Системная файловая таблица одна и
совместно используется всеми процессами.</p> 

<p>Как следует из рис. 4.12,
несколько записей системной файловой таблицы могут адресовать один и тот же
файл, который представлен единственной записью в таблице vnode.</p> 

<h3>Файловые дескрипторы</h3> 

<p>Файловый дескриптор представляет собой неотрицательное
целое число, возвращаемое&nbsp;&nbsp;
системными&nbsp;&nbsp; вызовами,&nbsp;&nbsp; такими&nbsp;&nbsp;
как&nbsp;&nbsp; <i style='mso-bidi-font-style:
normal'>creat</i><i 
style='mso-bidi-font-style:normal'>(2),&nbsp;&nbsp; </i><i style='mso-bidi-font-style:
normal'>open</i><i 
style='mso-bidi-font-style:normal'>(2)</i> или <i 
style='mso-bidi-font-style:normal'>pipe(2).</i> После
получения файлового дескриптора процесс может использовать его для дальнейшей
работы с файлом, например с помощью системных вызовов <i 
style='mso-bidi-font-style:normal'>read(2), write(2), close(2)</i> или <i 
style='mso-bidi-font-style:normal'>fcntl(2)</i>.</p> 

<p>Ядро&nbsp;&nbsp;
обеспечивает&nbsp;&nbsp; работу&nbsp;&nbsp; процесса&nbsp;&nbsp;
с&nbsp;&nbsp; файлами,&nbsp;&nbsp; используя&nbsp;&nbsp;
различные структуры данных, часть из которых расположена в u-area процесса.
Напомним, что эта область описывается структурой user. В табл. 4.7 приведены поля структуры user, которые используются ядром для обеспечения доступа процесса к файлу.</p> 

<p><img width=493 height=104
src="4файловаподсистема.files/image052.jpg" v:shapes="_x0000_i1050"></p> 

<p>Файловый
дескриптор связан с этими двумя полями и, таким образом, обеспечивает доступ к
соответствующему элементу файловой таблицы (структуре данных file).</p> 

<p>В
настоящее время в качестве единственного флага файлового дескриптора определен
флаг FD_CLOEXEC. Если
этот флаг установлен, то производится закрытие файлового дескриптора
(аналогично явному вызову close(2) при выполнении процессом системного вызова ехес(2)).&nbsp;
При этом для запущенной программы не происходит наследования
файлового дескриптора доступа к файлу.</p> 

<p>Более
старые версии UNIX используют статическую
таблицу дескрипторов, которая целиком хранится в u-area. Номер
дескриптора является индексом этой таблицы. Таким образом, размер таблицы,
которая обычно содержит 64 элемента, накладывает ограничение на число
одновременно открытых процессом файлов. В современных версиях таблица
размещается динамически и может увеличиваться при необходимости. Следует,
однако иметь в виду, что и в этом случае максимальное число одновременно
открытых файлов регламентируется пределом RLIMIT_NOFILE, которая
рассматривался в разделе &quot;Ограничения&quot; главы 2. В некоторых версиях
например, Solaris 2.5, данные файловых
дескрипторов хранятся не в таблицы, а в виде блоков структур uf_entry, поля
которой аналогичны приведенным в табл. 4.7.</p> 

<p>Содержимое
таблицы дескрипторов процесса можно посмотрено с помощью утилиты <i 
style='mso-bidi-font-style:normal'>crash(lM)</i>. Команда user покажет содержимое u-area процесса.
Например, для текущего командного интерпретатора мы
получим следующую информацию:</p> 

<p><img width=415 height=420
src="4файловаподсистема.files/image054.jpg" v:shapes="_x0000_i1051"></p> 

<h3>Файловая таблица</h3> 

<p>Поля
файлового дескриптора u_ofile и u_pofile содержат начальную информацию,
необходимую для доступа процесса к данным файла. Дополнительная информация
находится в системной файловой таблице и таблице индексных дескрипторов. Для
обеспечения доступа процесса к данным файла ядро должно полностью создать
цепочку от файлового дескриптора до vnode и, соответственно, до блоков хранения данных, как
показано на рис. 4.12.</p> 

<p>Каждый элемент файловой таблицы содержит информацию,
необходимую для управления работой с файлом. Если несколько процессов открывают
один и тот же файл, каждый из них получает собственный элемент файловой
таблицы, хотя все они будут работать с одним и тем же файлом. Важнейшие поля
элемента файловой таблицы приведены ниже:</p> 

<div style='mso-element:frame;mso-element-frame-height:402.1pt;mso-element-frame-hspace:
1.8pt;mso-element-frame-vspace:2.9pt;mso-element-wrap:no-wrap-beside;
mso-element-anchor-vertical:paragraph;mso-element-anchor-horizontal:margin;
mso-element-left:

<table cellspacing=0 cellpadding=0 hspace=0 vspace=0 height=544>
 <tr> 
  <td valign=top align=left height=544 style=' padding-top:2.9pt;padding-right:
  1.8pt;padding-bottom:2.9pt;padding-left:1.8pt'>
  <p><img width=499 height=536
  src="4файловаподсистема.files/image056.jpg" v:shapes="_x0000_i1052"></p> 
</div> 

<p>Для иллюстрации
обсуждения продолжим работу с утилитой <i>crash(1М).&nbsp; </i>С помощью команды <i>user </i>в предыдущем разделе
были получены адреса элементов файловой таблицы для стандартного ввода (fd=0),
вывода (fd=1) и вывода сообщений об ошибках (fd=2).
Заметим, что все они указывают на один и тот же элемент. С помощью команды <i>file</i> исследуем его содержимое:</p> 

<p><img width=481 height=111
  src="4файловаподсистема.files/image058.jpg" v:shapes="_x0000_i1053"></p> 

<p>Поскольку это специальный файл устройства (об этом
свидетельствует поле TYPE эдемента файловой таблицы),
поле v_data (vdata) vnode указывает на inode файловой
системы ufs, а на snode –
индексный дескриптор логической файловой системы specfs,&nbsp;
обслуживающей&nbsp; специальные файлы
устройств. Более подробно этот интерфейс будет рассматриваться в следующей
главе. Таким образом, для продолжения путешествия по структурам данных ядра,
следует обратиться к snode, адрес
которого указан в поле VDATA.</p> 

<p><img width=493 height=59
src="4файловаподсистема.files/image060.jpg" v:shapes="_x0000_i1054"></p>
<p>Поле s_realvp (REALVP)
указывает на vnode файла реальной файловой
системы (в данном случае ufs). Поэтому
далее поиск аналогичен проделанному при исследовании
таблицы монтирования.</p> 

<p><img width=469 height=144
src="4файловаподсистема.files/image062.jpg" v:shapes="_x0000_i1055"></p> 

<p>В результате мы
определили имя специального файла устройства (в данном случае – это
псевдотерминал), на которое производится ввод и вывод командного
интерпретатора.</p> 

<h3>Блокирование
доступа к файлу</h3> 

<p>Традиционно&nbsp;
архитектура&nbsp; файловой&nbsp; подсистемы&nbsp;
UNIX&nbsp; разрешает&nbsp; нескольким
процессам одновременный доступ к файлу для чтения и записи. Хотя операции
записи и чтения, осуществляемые с помощью системных вызовов read(2) или write(2),
являются атомарными, в UNIX по умолчанию отсутствует синхронизация между отдельными вызовами.
Другими словами, между двумя
последовательными вызовами read(2) одного процесса другой может модифицировать данные
файла. Это, в частности, может привести к несогласованным операциям с файлом, и как следствие, к
нарушению целостности его данных. Такая ситуация является неприемлемой для многих приложений.</p> 

<p>UNIX позволяетляет обеспечить блокирование заданного диапазона байтов файла
или записи файла.&nbsp; Для этого
служат базовый&nbsp; системный&nbsp; вызов управления файлом fcntl(2) и библиотечная функция lockf(3C), предназначенная специально для управления блокированием. При этом
фактической файловой операцией (чтения или записи) процесс устанавливает
блокирование соответствующего типа (для чтения или для записи). Если
блокирование завершилось успешно, это означает, что требуемая файловая операция
не создаст конфликта или нарушения целостности данных,&nbsp; например, при одновременной записи в файл
несколькими процессами.</p> 

<p>По умолчанию
блокирование является рекомендательным
(advisory lock). Это означает, что кооперативно работающие процессы могут
руководствоваться созданными блокировками, однако ядро не запрещает чтение или
запись в заблокированный участок файла. При работе с рекомендательными
блокировками процесс должен явно проверять их наличие с помощью тех же функций fcntl(2) и lockf(3C).</p> 

<p>Мы уже встречались с использованием системного вызова fcntl(2) для блокирования записей файла в главе 2. Там же была упомянута
структура flock, служащая для описания
блокирования. Поля этой структуры описаны в табл. 4.8.</p> 

<div style='mso-element:frame;mso-element-frame-height:216.0pt;mso-element-frame-hspace:
1.8pt;mso-element-frame-vspace:2.9pt;mso-element-wrap:no-wrap-beside;
mso-element-anchor-vertical:paragraph;mso-element-anchor-horizontal:margin;
mso-element-left:

<table cellspacing=0 cellpadding=0 hspace=0 vspace=0 height=296>
 <tr> 
  <td valign=top align=left height=296 style=' padding-top:2.9pt;padding-right:
  1.8pt;padding-bottom:2.9pt;padding-left:1.8pt'>
  <p><img width=488 height=288
  src="4файловаподсистема.files/image064.jpg" v:shapes="_x0000_i1056"></p> 
</div> 

<p>Как
следует из описания поля l_type структуры flock,
существуют два типа блокирования записи: для чтения (f_rdlck) и для записи (F_WRLCK).
Правила блокирования таковы,&nbsp; что&nbsp; может быть установлено несколько блокирований
для чтения на конкретный байт файла, при этом в установке блокирования для
записи на этот байт будет отказано. Напротив, блокирование для записи на
конкретный байт должно быть единственным, при этом в установке блокирования для
чтения будет отказано.</p> 

<p>Приведем
фрагмент программы,&nbsp; использующей&nbsp; возможность блокирования записей:</p> 

<p><img width=498 height=216
src="4файловаподсистема.files/image066.jpg" v:shapes="_x0000_i1057"></p> 

<p>В отличие от
рекомендательного в UNIX существует <i 
style='mso-bidi-font-style:normal'>обязательное
блокиро&shy;вание</i> (mandatory lock), при котором ограничение на доступ к записям файла
накладывается самим ядром. Реализация обязательных блокировок может быть
различной. Например, в SCO UNIX (SVR3) снятие бита х для группы
и установка бита SGID для группы приводит к тому, что блоки&shy;ровки,
установленные fcntl(2)
или lockf(3C)t станут обязательными. UNIX SVR4 поддерживает установку блокирования отдельно для
записи и для чтения, обеспечивая тем самым доступ для чтения многим, а для
записи — только одному процессу. Эти установки также осуществляются с помощью
системного вызова fcntl(2).
Следует иметь в
виду, что использование обяза&shy;тельного блокирования таит потенциальную
опасность. Например, если процесс блокирует доступ к жизненно важному
системному файлу и по каким-либо причинам теряет контроль, это может привести к
аварийному останову операционной системы.</p> 

<h3>Буферный кэш</h3> 

<p>Во введении отмечалось, что
работа файловой подсистемы тесно связана с обменом данными с периферийными
устройствами. Для обычных файлов и каталогов — это устройство, на котором
размещается соответствующая файловая система, для специальных файлов устройств
– это принтер, терминал, или сетевой адаптер. Не вдаваясь в подробности
подсистемы ввода/вывода, рассмотрим, как во многих версиях UNIX
организован обмен данными с дисковыми устройствами — традиционным местом хранения
подавляющего большинства файлов<sup>1</sup>.</p> 

<p><font size="2">1 На самом деле&nbsp;
файловые&nbsp; системы&nbsp;&nbsp; могут&nbsp;&nbsp;
располагаться&nbsp;&nbsp; на&nbsp;&nbsp; удаленных&nbsp;&nbsp;
компьютерах ( например, в случае NFS). Хотя при работе с такими файловыми
системами дисковый ввод/вывод отсутствует, тем не менее и в этом случае
кэширование блоков данных значительно повышает производительность.</font></p> 

<p>Не секрет, что операции
дискового ввода/вывода являются медленными по сравнению, например, с доступом к
оперативной или сверхоперативной памяти. Время чтения данных с диска и
копирования тех же данных в памяти может различаться в несколько тысяч раз.
Поскольку основные данные хранятся на дисковых накопителях, дисковый ввод/вывод
является узким местом операционной системы. Для повышения производительности
дискового ввода/вывода и, соответственно, всей системы в целом, в UNIX
используется кэширование дисковых блоков в памяти.</p> 

<p>Для
этого используется выделенная область оперативной памяти, где кэшируются
дисковые блоки файлов, к которым наиболее часто осуществляется доступ. Эта
область памяти и связанный с ней процедурный интерфейс носят название <i 
style='mso-bidi-font-style:normal'>буферного
кэша</i>, и через него проходит
большинство операций файлового ввода/вывода. Схема взаимодействия различных
подсистем ядра с буферным кэшем приведена на рис. 4.13.</p> 

<p><img width=403 height=490
src="4файловаподсистема.files/image068.jpg" v:shapes="_x0000_i1058"></p> 

<h3>Внутренняя структура
буферного кэша</h3> 

<p>Буферный кэш состоит из буферов данных, размер которых
достаточен для размещения одного дискового блока. С каждым блоком данных связан
<i 
style='mso-bidi-font-style:normal'>заголовок буфера</i>, представленный структурой buf, с помощью
которого ядро производит управление кэшем, включая идентификацию и поиск
буферов, а
также синхронизацию доступа. Заголовок также используется при обмене данными с
драйвером устройства для выполнения фактической операции ввода/вывода. Когда возникает необходимость чтения или записи буфера на диск, ядро заносит
параметры операции ввода/вывода в заголовок и передает его функции драйвера
устройства.&nbsp; После завершения операции ввода/вывода заголовок содержит
информацию о ее результатах.</p> 

<p>Основные поля структуры buf приведены в
табл. 4.9.</p> 

<p><img width=498 height=237
src="4файловаподсистема.files/image070.jpg" v:shapes="_x0000_i1059"></p> 

<p>Поле b_flags хранит различные флаги связанного с заголовком
буфера. Часть
флагов используется буферным кэшем, а часть — драйвером устройств. Например, с
помощью флага b_busy осуществляется синхронизация
доступа к буферу. Флаг b_delwri отмечает буфер как модифицированный,
или &laquo;грязный&raquo;, требующий сохранения на диске перед повторным использованием.
Флаги b_read, b_write, b_async, b_done и b_error используются драйвером
диска. Более подробно операция ввода/вывода для драйвера будет рассмотрена в
следующей главе.</p> 

<p>Буферный
кэш использует механизм отложенной
записи (write-behind), при котором модификация буфера не вызывает
немедленной записи на диск. Такие буферы отмечаются как &quot;грязные&quot;, а
синхронизация их содержимого с дисковыми данными происходит через определенные
промежутки времени. Примерно одна треть операций дискового ввода/вывода
приходится на запись, причем один и тот же буфер может на протяжении
ограниченного промежутка времени модифицироваться несколько раз. Поэтому
буферный кэш позволяет значительно уменьшить интенсивность записи на диск<sup>2</sup> 
и реорганизовать последовательность записи отдельных
буферов и повышения производительности ввода/вывода (например, уменьшая время
поиска, группируя запись соседних дисковых блоков). Однако механизм имеет свои
недостатки, поскольку может привести к нарушению целостности файловой системы в
случае неожиданного останова операционной системы.</p> 

<p><font size="2">2 Использование буферного кэша позволяет
избежать 95% операций чтения с операций записи на диск для типичной
конфигурации операционной систем</font></p> 

<h3>Операции ввода/вывода</h3> 

<p>На рис. 4.14 представлена
схема выполнения операций ввода/вывода с пользованием буферного кэша.&nbsp; Важной особенностью этой подсистемы является
то, что она обеспечивает независимое выполнение операций чтения или записи
данных процессом как результат соответствующие системных вызовов, а также
фактический обмен данными с периферийным устройством.</p> 

<p>Когда процессу требуется
прочитать или записать данные он использует системные вызовы read(2) или write(2), направляя тем самым запрос
файловой подсистеме. В свою очередь файловая подсистема транслирует этот запрос
в запрос на чтение или запись соответствующих дисковых блоков фай&shy;ла и
направляет его в буферный кэш. Прежде всего кэш просматривается предмет наличия
требуемого блока в памяти. Если соответствующий буфер найден, его содержимое
копируется в адресное пространство процесса в случае чтения и наоборот при
записи, и операция завершается. Если блок в кэше не найден, ядро размещает
буфер, связывает его с дисковым блоком с помощью заголовка buf и
направляет запрос на чтение драйверу устройства. Обычно используется схема чтения вперед (read-ahead),
когда считываются не только запрашиваемые блоки, но и блоки, которые с высокой
вероятностью могут потребоваться в ближайшее время (рис. 4.14, а). Таким
образом, последующие вызовы read(2)
скорее
всего&nbsp; не&nbsp;
потребуют дискового ввода/вывода, а будут включать лишь копирование
данных из буферов в память процесса, — операция, которая, как отмечалось,
обладает на несколько порядков большей производительностью (рис. 4.14, б—в).
При запросе на модификацию блока изменения также затрагивают только буфер кэша.
При этом ядро помечает буфер как &quot;грязный&quot; в заголовке buf
(рис. 4.14, г). &nbsp;Перед освобождением такого буфера для
повторного использования, содержимое должно быть предварительно сохранено на
диске (рис. 4.14, д).</p> 

<p>Перед
фактическим использованием буфера, например при чтении или записи буфера
процессом, или при операции дискового ввода/вывода, доступ к нему для других
процессов должен быть заблокирован. При обращении к уже заблокированному буферу
процесс переходит в состояние сна, пока данный ресурс не станет доступным.</p> 

<p><img width=393 height=548
src="4файловаподсистема.files/image072.jpg" v:shapes="_x0000_i1060"></p> 

<p>Не заблокированные буферы помечаются как свободные и
помещаются в специальный&nbsp; список.&nbsp;&nbsp; Буферы&nbsp;
в этом списке располагаются в порядке наименее частого использования (Least Recently Used, LRU). Таким образом, когда ядру необходим буфер, оно
выбирает тот, к которому не было обращений в течение наиболее продолжительного
промежутка времени. После того как работа с буфером завершена, он помещается в
конец&nbsp; списка и является наименее
вероятным кандидатом на освобождение и повторное использование. Поэтому, если
процесс вскоре опять обратится к тому же блоку данных, операция ввода/вывода
по-прежнему будет происходить с буфером кэша. С течением времени буфер
перемещается в направлении начала очереди, но при каждом последующем обращении
к нему, будет помещен в ее конец.</p> 

<p>Основной проблемой, связанной с буферным кэшем,
является &laquo;старение&raquo; информации, хранящейся в дисковых блоках, образы которых
находятся в буферном кэше. Как следует из схемы работы кэша, большинство
изменений затрагивают только данные в соответствующих буферах, в то время как
дисковые блоки хранят уже устаревшую информацию. Разумеется в нормально
работающей системе проблемы как таковой не возникает, поскольку в операциях
ввода/вывода&nbsp; всегда&nbsp; используются свежие данные буферного&nbsp; кэша.&nbsp;&nbsp;
Однако&nbsp; при аварийном&nbsp; останове&nbsp;
системы, это может привести к потере изменений данных файлов, сделанных
процессами не&shy;посредственно перед остановом.</p> 

<p>Для уменьшения вероятности таких потерь в&nbsp; UNIX
имеется несколько возможностей:</p> 

<p>Во-первых, может использоваться системный вызов sync(2),
который обновляет все дисковые блоки,
соответствующие &quot;грязным&quot; буфера. Необходимо отметить, что sync(2)
не ожидает завершения операции
ввода/вывода, таким образом после возврата из функции не гарантируется, что все
&quot;грязные&quot; буферы сохранены на диске<sup>3</sup>.</p> 

<p>Во-вторых, процесс может открыть файл в синхронном
режиме (указав флаг О_SYNC в системном
вызове ореn(2)).
При этом все изменения в файле будут
немедленно сохраняться на диске.</p> 

<p>Наконец, через регулярные
промежутки времени в системе пробуждается специальный системный процесс —
диспетчер буферного кэша (в различных версиях UNIX его названия отличаются, чаще используется&nbsp;&nbsp;&nbsp; fsflush&nbsp;&nbsp;&nbsp; или&nbsp;&nbsp;&nbsp;
bdflush).&nbsp;&nbsp;&nbsp; Этот&nbsp;&nbsp;&nbsp; процесс&nbsp;&nbsp;&nbsp;
освобождает &quot;грязные&quot;
буферы, сохраняя их содержимое в соответствующих дисковых блоках<sup>4</sup> (рис. 4.14,
д).</p> 

<p><font size="2">3 В распоряжении администратора имеется командный интерфейс
к системному вызову – утилита </font><i><font size="2">sync(lM). </font></i><font size="2">Поскольку выполнение команды еще не свидетельствует о фактическом завершении
ввода/вывода, администраторы практикуют вызов </font><i><font size="2">sync(lM) </font></i><font size="2">несколько раз. Повторные вызовы повышают вероятность того, что
ввод/вывод будет завершен прежде, чем будет введена другая команда или
остановлена система, поскольку набор команды занимает определенное время. Тот же
эффект может быть достигнут просто ожидая скольких секунд после ввода </font><i><font size="2">sync(lM), </font></i><font size="2">но набор команды
позволяет &laquo;скрасить ожидание&raquo;.</font></p> 

<p><font size="2">4 Работа диспетчера буферного кэша зависит от версии UNIX
и конкретных настроек ядра системы. Например, в SCO UNIX
для этого используются несколько параметров. Параметр BDFLUSHR задает интервал между
последовательными пробуждениями bdflush, его значение по умолчанию составляет
30 секунд. Параметр NAUTOUP задает промежуток
времени, который буфер должен оставаться &quot;грязным&quot;, прежде чем bdflush сохранит его на диске.</font></p> 

<h3>Кэширование в SVR4</h3> 

<p>Центральной концепцией в архитектуре виртуальной
памяти SVR4 является изображение файлов. При этом подходе все
адресное пространство может 6ьггь представлено набором отображений различных
файлов в память. Действительно, в страницы памяти, содержащие кодовые сегменты,
отображаются соответствующие секции исполняемых файлов. Процесс может задать
отображение&nbsp; с&nbsp; помощью&nbsp;
системного&nbsp; вызова&nbsp; mmap(2),&nbsp; при&nbsp; этом страницам памяти будут соответствовать
определенные участки отображаемого файла. Даже области памяти, содержимое
которых изменяется и не связано ни с каким файлом файловой системы, т. н. анонимные страницы, можно отобразить
на определенные участки специального файла устройства, отвечающего за область
свопинга (именно там сохраняются ано&shy;нимные объекты памяти). При этом
фактический обмен данными между памятью&nbsp;
и&nbsp; устройствами&nbsp;&nbsp; их хранения,&nbsp;&nbsp; инициируется&nbsp;
возникновением страничной ошибки. Такая архитектура позволяет
унифицировать опера&shy;ции ввода/вывода практически для всех случаев.</p> 

<p>При этом подходе, когда процесс выполняет вызовы read(2)
или write(2), ядро устанавливает отображение части файла,
адресованного этими вызо&shy;вами, в собственное адресное пространство. Затем эта
область копируется в адресное пространство процесса. При копировании возникают
странич&shy;ные ошибки, приводящие в фактическому считыванию дисковых блоков файла
в память. Поскольку все операции кэширования данных в этом слу&shy;чае
обслуживаются подсистемой управления памятью, необходимость в буферном кэше,
как отдельной подсистеме, отпадает.</p> 

<h3>Целостность файловой системы</h3> 

<p>Значительная часть файловой системы находится в
оперативной памяти. А именно,&nbsp; в оперативной
памяти расположены суперблок примонтированной системы, метаданные активных
файлов (в виде системно-зависимых inode и
соответствующих им vnode) и даже отдельные блоки
хранения данных файлов, временно находящиеся в буферном кэше.</p> 

<p>Для операционной системы рассогласование между буферным кэшем и блоками хранения данных
отдельных файлов, не приведет к катастрофическим последствиям даже в случае
внезапного останова системы, хотя с точки зрения пользователя все может
выглядеть иначе. Содержимое отдельных файлов не вносит существенных нарушений в
целостность файловой системы.
</p> 

<p>Другое дело, когда подобные
несоответствия затрагивают метаданные файла или другую управляющую информацию
файловой системы, например, суперблок. Многие файловые операции затрагивают сразу
несколько объектов файловой системы, и если на диске будут сохранены изменения
только для части этих объектов,&nbsp;
целостность файловой систем может быть существенно нарушена.</p> 

<p>Рассмотрим пример создания жесткой связи для файла. Для этого
файловой подсистеме необходимо выполнить следующие операции:</p> 

<ol type="1">
    <li>Создать новую запись в необходимом
каталоге, указывающую на inode<br> 
файла.</li>
    <li>Увеличить счетчик связей в inode.</li>
</ol>
<p>Предположим, что аварийный останов
системы произошел между первой и второй операциями. В этом случае после запуска
в файловой системе будут существовать два имени файла (две записи каталогов),
адресующие inode со счетчиком связей di_nlinks,&nbsp;&nbsp; равным 1. Эта ситуация показам на рис. 4.15
(а). Если теперь будет удалено одно из имен, это приведет удалению файла как
такового, т. е. к освобождению блоков хранения данных и inode, поскольку счетчик связей di_nlinks&nbsp;&nbsp; станет равным 0. Оставшаяся запись каталога
будет указывать на неразмещенный индексный дескриптор, или inode, адресующий уже другой файл (рис. 4.15, б).</p> 

<p>Порядок операций с метаданными может
иметь существенное влияние на целостность файловой системы. Рассмотрим,
например, предыдущий пример. Допустим, порядок операций был изменен и, как и
прежде, останов произошел между первой и второй операциями. После запуска файл
будет иметь лишнюю жесткую связь, но существующая
запись каталога останется правильной. Тем не менее при
удалении имени файла фактически файл удален не будет, поскольку число связей
останется равным 1 (рис. 4.15, в). Хотя это также является ошибкой, результатом
которой является засорение дискового пространства, ее последствия все же менее
катастрофичны, чем в первом случае.</p> 

<p>Ядро выбирает
порядок совершения операций с метаданными таким образом, чтобы вред от ошибок в
случае аварии был минимальным. Однако проблема нарушения этого порядка все же
остается, т. к. изменять&nbsp;&nbsp;
очередность&nbsp;&nbsp; выполнения&nbsp;&nbsp; запросов&nbsp;&nbsp;
для&nbsp;&nbsp; оптимизации
ввода/вывода.&nbsp; Единственной&nbsp; возможностью сохранить выбранный порядок
является&nbsp;&nbsp; синхронизация&nbsp; операций&nbsp;&nbsp;
со&nbsp; стороны&nbsp;&nbsp; файловой подсистемы.</p> 

<p>В нашем примере файловая подсистема будет ожидать, пока на диск будет
записаано содержимое индексного дескриптора, и только после этого произведет
изменения каталога.</p> 

<p><img width=395 height=536
src="4файловаподсистема.files/image074.jpg" v:shapes="_x0000_i1061"></p> 

<p>&nbsp;</p> 

<p>Отсутствие синхронизации между образом файловой системы в
памяти и ее данными на диске в случае аварийного останова может привести к
появлению следующих ошибок:</p> 

<ol type="1">
    <li>Один блок адресуется несколькими inode (принадлежит нескольким
файлам).</li>
    <li>Блок помечен как свободный, но в то же время занят (на него ссылается inode).</li>
    <li>Блок помечен как занятый, но в то же время свободен (ни один inode на
него не ссылается).</li>
    <li>Неправильное число ссылок в inode (недостаток или избыток
ссылающихся записей в каталогах).</li>
    <li>Несовпадение между размером файла и суммарным размером адресуемых inode
блоков.</li>
    <li>Недопустимые адресуемые блоки (например, расположенные за пределами
файловой системы).</li>
    <li>&quot;Потерянные&quot; файлы (правильные inode, на которые не ссылаются
записи каталогов).</li>
    <li>Недопустимые или
неразмещенные номера inode в записях
каталогов.</li>
</ol>
<p>Эти ошибки схематически
показаны на рис. 4.16.</p> 

<p>&nbsp;<img width=485 height=404
  src="4файловаподсистема.files/image076.jpg" v:shapes="_x0000_i1062"></p> 

<p>Если нарушение все же
произошло, на помощь может прийти утилита fsck(1M), производящая исправление файловой системы. Запуск этой
утилиты может производиться автоматически каждый раз при запуске системы, или администратором, с
помощью команды:</p> 

<p>fsck&nbsp; [options]&nbsp;&nbsp; filesystem</p> 

<p>где filesystem&nbsp; —&nbsp; специальный файл устройства, на котором находится
файловая система.</p> 

<p>Проверка и исправление должны
производиться только на размонтированной файловой&nbsp; системе.&nbsp;
Это&nbsp; связано&nbsp; с&nbsp;
необходимостью&nbsp; исключения синхронизации таблиц в памяти
(ошибочных) с их дисковыми эквивалентами (исправленными). Исключение составляет
корневая файловая система, которая не может быть размонтирована. Для ее
исправления необходимо использовать опцию
-b, обеспечивающую немедленный перезапуск системы после проведения
проверки.</p> 

<h3>Заключение</h3> 

<p>В этой главе описана
организация файловой подсистемы UNIX. Начав разговор с
обсуждения архитектуры традиционных файловых систем UNIX, мы остановились на анализе
т. н. виртуальной файловой системы, обеспечивающей единый интерфейс доступа к
различным типам физиче&shy;ских файловых систем.</p> 

<p>Мы также рассмотрели, каким
образом происходит доступ процесса к данным, хранящимся в файлах, вплотную
подошли к разговору о подсис&shy;теме ввода/вывода, который и продолжим в следующей
главе.</p> 

</body> 

</html> 
